{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c37f142e-0ba5-45ee-896b-3e2ef32b6f60",
   "metadata": {},
   "source": [
    "# Neural Networks with a Deep Learning Framework - PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cbb9e6-1c90-486f-bb50-30bd809862a9",
   "metadata": {},
   "source": [
    "1. In Practical9a.ipynb, we will first look at the same problem from the Practical 8 - classification of sklearn \"moons\".\n",
    "2. Then, in Practical9b.ipynb, we will look at a far more complex problem of classification of hand-written numbers in the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f2d4b-df9d-4ded-bdab-c7ff217394e7",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b7ed5-5bf0-4da5-a9a4-2433000ed4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b23bac-bcfc-43f7-93c1-a6a052ac2681",
   "metadata": {},
   "source": [
    "__Load dataset__\n",
    "- `train.csv` is a copy of the MNIST dataset (torchvision.datasets.MNIST()) that has been converted from image data to numerical CSV data\n",
    "- change 'm22oc' to 'm22ext' as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b6cb3-1247-4ccb-a849-7b983f8ac08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"/work/m22oc/m22oc/shared/DAwHPC/practicals_data/NeuralNetworksPyTorch/MNIST.csv\",dtype = np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e2a298-4ae4-43e4-bb64-4181a8e5a5b3",
   "metadata": {},
   "source": [
    "- Each row is an image\n",
    "- The label represents the handwritten number\n",
    "- pixel0 to pixel783 represent a 28x28 pixel image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a3bbf-96ec-4ded-940c-df895f92556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0b9a0-80d6-4583-bb55-babf52b58d10",
   "metadata": {},
   "source": [
    "__Pre-process the data for ingest into the model__\n",
    "- split data into features (pixels) and labels (numbers from 0 to 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685580e-e88a-4089-9845-f3f0d58878f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_targets = train.label.values\n",
    "np_features = train.loc[:,train.columns != \"label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900d9d2-acab-4265-ab30-c6fe41b0c5c1",
   "metadata": {},
   "source": [
    "Normalise the features (256 colour images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5260649-2bd2-44a8-b063-4dc90dfd9baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np_features[np.where(np_features != 0)]) # before normalisation, values range from 0 to 255\n",
    "#write code to normalise np_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c24f09-b406-4686-91c0-381742659562",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_features[np.where(np_features != 0)] # after normalisation, values range from 0 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ec5c2-c765-4837-801c-a873ee687cea",
   "metadata": {},
   "source": [
    "Split into 80:20 train:test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65369482-dc80-424b-8087-27cfbc4527ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_features_train, np_features_test, np_targets_train, np_targets_test = train_test_split(np_features,\n",
    "                                                                                          np_targets,\n",
    "                                                                                          test_size=0.2,\n",
    "                                                                                          random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f8f0b-7117-45de-9bf6-d8e21e4d575a",
   "metadata": {},
   "source": [
    "Convert to torch.Tensor\n",
    "- note we can convert from float32 (used by default in the numpy arrays) to torch datatypes, such as `torch.LongTensor` for the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c06560c-36ec-48a6-867b-afde9fb78a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_train = torch.from_numpy(np_features_train)\n",
    "targets_train = torch.from_numpy(np_targets_train).type(torch.LongTensor)\n",
    "\n",
    "features_test = torch.from_numpy(np_features_test)\n",
    "targets_test = torch.from_numpy(np_targets_test).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22b83ae-6f98-48b7-a4ed-3aec72552c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34d261-bbb5-41d9-8f37-e62878751acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some images\n",
    "figure = plt.figure()\n",
    "num_of_images = 60\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np_features[index].reshape((28,28)), cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1568871-49ee-48eb-bc87-33b95d7e2a4b",
   "metadata": {},
   "source": [
    "At this stage we have torch.Tensor object representing our data.\n",
    "\n",
    "Now, we need to construct \n",
    "- torch.autograd.Variable objects - these will store our tensors and gradients\n",
    "- torch.utils.data.DataLoader objects - these will provide the funcionality required to divide our images into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a36da7f-ca32-4d08-b14b-ee81a38793d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine feature and target combinations into train and test sets \n",
    "train = torch.utils.data.TensorDataset(features_train,targets_train)\n",
    "test = torch.utils.data.TensorDataset(features_test,targets_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a8919-2140-475a-8eb7-868d99c46eac",
   "metadata": {},
   "source": [
    "This is also a useful stage to decide on hyperparameters, since one of them, `batch_size`, is required on DataLoader initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59f90d-af5f-40cb-b829-fbbd3906906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some hyperparameters\n",
    "batch_size = 100\n",
    "n_iters = 10000\n",
    "num_epochs = int(n_iters / (len(features_train) / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c354e5-7e6b-4ee1-bcc2-6ea53bc7522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise DataLoader objects\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd32c27-a00e-4301-9231-1ff0e88e4f16",
   "metadata": {},
   "source": [
    "__Now build a Logistic Regression model__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34007ae2-50a4-4133-8ef8-2f23776dd2d2",
   "metadata": {},
   "source": [
    "As we saw in Practical 9a, a model is defined as a Python class extending nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a1abe-aaa6-4bed-a640-a1d5868e31dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Logistic Regression Model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, n_features, n_outputs):\n",
    "        # initialise with Python super()\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        # linear regression activation\n",
    "        self.linear = nn.Linear(n_features, n_outputs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c26c2-89db-4952-871f-f53f77b83eca",
   "metadata": {},
   "source": [
    "And that's it!!\n",
    "\n",
    "But something is strange - the activation function is linear regression, not logistic regression...\n",
    "\n",
    "The logistic part is taken care of y the loss function, which will use `nn.CrossEntropyLoss()` as its error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f17cea-a75a-4fd3-89fd-ac1516265c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy Loss- note, this time we have 10 target outputs (classes) so we use CrossEntropyLoss() rather than BCELoss() (B is for Binary!)\n",
    "error = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d568328-b7e8-415e-b5c2-a040a28f9c97",
   "metadata": {},
   "source": [
    "Instantiate the model\n",
    "- fill in the numbers in place of `??`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356837fa-06ff-45bf-8677-b27c19f71606",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = ?? # number of pixels per image\n",
    "n_outputs = ??  # number of possible labels\n",
    "\n",
    "model = LogisticRegressionModel(n_features, n_outputs)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec35e9-34bc-4b48-8e51-646b92431059",
   "metadata": {},
   "source": [
    "Use Stochastic Gradient Descent as in Practical9a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60657ee-8598-4708-891e-6577298bb852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another hyperparameter is learning rate\n",
    "learning_rate = 0.001\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c83beb-c614-4c88-905b-282fe7ffe13c",
   "metadata": {},
   "source": [
    "Now, let's put our training loop in a function.\n",
    "- add code below comments in place of `??`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab7dd1c-3669-4456-9309-67dbd4d9f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "iterations = []\n",
    "def train_LogisticRegressionModel(model, num_epochs, train_loader, error, optimiser):\n",
    "    count = 0\n",
    "    global losses\n",
    "    global iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Define variables\n",
    "            train = Variable(images.view(-1, 28*28))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Clear gradients\n",
    "            ??\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = ??\n",
    "\n",
    "            # Calculate softmax and cross entropy loss\n",
    "            loss = ??\n",
    "\n",
    "            # Calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimiser.step()\n",
    "\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                # Calculate Accuracy         \n",
    "                correct = 0\n",
    "                total = 0\n",
    "                # Predict test dataset\n",
    "                for images, labels in test_loader: \n",
    "                    test = Variable(images.view(-1, 28*28))\n",
    "\n",
    "                    # Forward propagation\n",
    "                    outputs = model(test)\n",
    "\n",
    "                    # Get predictions from the maximum value\n",
    "                    predicted = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "                    # Total number of labels\n",
    "                    total += len(labels)\n",
    "\n",
    "                    # Total correct predictions\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "                accuracy = 100 * correct / float(total)\n",
    "\n",
    "                # store loss and iteration\n",
    "                losses.append(loss.data)\n",
    "                iterations.append(count)\n",
    "                \n",
    "                # Print Loss and accuracy\n",
    "                ??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93098739-56f8-46f6-8378-910def0fae27",
   "metadata": {},
   "source": [
    "Run optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3eb5d9-9345-47c4-9d56-335e97bd51aa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "losses = []\n",
    "iterations = []\n",
    "train_LogisticRegressionModel(model, num_epochs, train_loader, error, optimiser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf078c78-add6-4201-bbb1-2aadaf9d33ae",
   "metadata": {},
   "source": [
    "Visualise the optimisation progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ece10-d5d8-4e94-b231-8b934b68e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterations,losses)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Logistic Regression: Loss vs Iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d51bc-6bbe-414a-8132-e488b1bc83fe",
   "metadata": {},
   "source": [
    "_Run the training a few times - notice what happens to the loss and accuracy values, and the plot._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e702818-85b9-4a0c-84e6-5df0143d0335",
   "metadata": {},
   "source": [
    "Another useful visualisation is the probability that an image falls into a given class.\n",
    "We'll do that for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d04f37-4c86-4256-a5d1-5f75a5341b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(img, probab):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    probab = probab.squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), probab)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "    plt.xlabel(f\"Predicted Digit = {np.argmax(probab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dca930-50e4-4448-92de-91333f8fef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "#select a random image\n",
    "random_index = randint(0,len(images)-1)\n",
    "img = images[random_index].view(1, 784)\n",
    "\n",
    "#generate the inference for that image\n",
    "#this gives the log probabilities\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "#convert to probabilities\n",
    "ps = torch.exp(logps).numpy()[0]\n",
    "probab = ps / np.sum(ps)\n",
    "view_classify(img.view(1, 28, 28), probab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b18e2-bf39-46a6-8e98-eebf7d74625c",
   "metadata": {},
   "source": [
    "_Run the cell above multiple times to see some random images and their predicted classes._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aacc1c-09a8-4fe3-b988-e2dcc17e9585",
   "metadata": {},
   "source": [
    "Finally, save the model for future use - training is expensive, it's good practice to save the model so those resources are needed again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcba178-b9aa-47fd-8b6a-e76cd45077a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '9b_model.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff5e173-a472-487d-a6d4-101adc8fef54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
