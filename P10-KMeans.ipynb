{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practical: k-means\n",
    "==\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 1 - Hard coded k-means\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing $k$-means\n",
    "- In this first part of the practical we're going to implement $k$-means from scratch based on what we learnt in the lecture.\n",
    "- The file MyKmeans.py contains code that implements $k$-means clustering\n",
    "- Open the file and go through the function making sure you understand what every step does"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first simulate some data to use in our clustering and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(2)\n",
    "data=np.random.normal(size=250*2).reshape(250,2)\n",
    "data[0:124,0]=data[0:124,0]+3\n",
    "data[0:124,1]=data[0:124,1]-4\n",
    "\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.scatter(data[:,0],data[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run MyKmeans() in this dataset and see if we identify the two clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyKmeans import MyKmeans #this runs the contents of the file MyKeans.py that you examined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_df=pd.DataFrame(data)\n",
    "MyRes2 = MyKmeans(df=data_df,n_cluster=2, c_initial=range(2))\n",
    "print(MyRes2)\n",
    "plt.scatter(MyRes2.iloc[:,0],MyRes2.iloc[:,1], c=MyRes2.iloc[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From visual inspection it looks like $k$-means has done a pretty good job in separating the data into clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `crosstab()` from Pandas to compare the clusters' allocation with the true clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true=list([0]*125+[1]*125) #construct a list with \"true\" cluster number\n",
    "pd.crosstab(MyRes2.cluster,pd.Series(true), colnames=[\"True\"], rownames=[\"kmeans\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has it grouped all points correctly? Run the above for different numbers of clusters by adjusing `n_cluster` and `c_initial` and see how the clusters change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try also running it for different starting points to see whether and how the resulting clustering changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ⚠️❓HOW DOES THIS DIFFER FROM C_INITIAL ABOVE??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen in the lecture that $k$-means tries to minimize the total within cluster sum of squares. The function ***calculateSS()*** below takes as intput the results of MyKmeans and calculates the total, total within clusters and total between clusters sum of squares.\n",
    "\n",
    "Go through the function and make sure you understand how it works and the differences between each quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function calculateSS() \n",
    "#  Input: output from MyKmeans()\n",
    "#  Output: dataframe with Total within clusters, Between and Total Sum of Squares.\n",
    "\n",
    "def calculateSS(res_clusters):\n",
    "    \n",
    "    #Create a list with enough elements to store a number for each cluster referenced \n",
    "    Within_SS = [0]*int(res_clusters.iloc[:,res_clusters.shape[1]-1].max()+1)\n",
    "    \n",
    "    Total_SS = sum(res_clusters.iloc[:,0:res_clusters.shape[1]-1].apply(lambda x: sum((x-x.mean())**2), axis=1))\n",
    "    \n",
    "    for i in pd.unique(res_clusters.iloc[:,res_clusters.shape[1]-1]):\n",
    "        i=int(i)\n",
    "        df=res_clusters[res_clusters.cluster==i]\n",
    "        Within_SS[i] = sum(df.iloc[:,0:df.shape[1]-1].apply(lambda x: sum((x-x.mean())**2)))\n",
    "    \n",
    "    Total_Within_SS = sum(Within_SS)\n",
    "    \n",
    "    Between_SS = Total_SS-Total_Within_SS\n",
    "    \n",
    "    res=pd.DataFrame([[Total_Within_SS,Between_SS,Total_SS]])\n",
    "    res.columns=[\"Tot_Within\",\"Between\",\"Total\"]\n",
    "    \n",
    "    return(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateSS(MyRes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, we know that there are 2 clusters by construction. If we didn't, how would we choose $k$?\n",
    "\n",
    "We'd need to run MyKmeans for various values of $k$ and choose the one after which the reduction in total within clusters variation doesn't change much.\n",
    "\n",
    "Let's write a function that iteratively changes $k$ and each time calculates the total within clusters sum of squares using our `calculateSS()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_k(max_k, data):\n",
    "    #create placeholder lists with the correct number of elements\n",
    "    res = [0] * (max_k+1)\n",
    "    MySS = [0] * (max_k+1)\n",
    "    for i in range(1,max_k+1):\n",
    "        print(\"Trying k means with \",i,\" clusters\")\n",
    "        res[i]=MyKmeans(df=data, n_cluster=i, c_initial=range(i))\n",
    "        MySS[i]=calculateSS(res_clusters=res[i])\n",
    "    return MySS[1:max_k+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function on `data_df` for up to 10 clusters and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "k_res=choose_k(max_k=k, data=data_df)\n",
    "k_res=pd.concat(k_res, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1,11),k_res['Tot_Within'], 'o')\n",
    "plt.ylabel(\"Total Within SS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above plot, would anything stop you choosing $k=3$? Not really.\n",
    "\n",
    "Run `MyKmeans()` for 3 and 4 clusters and plot the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here\n",
    "MyRes4 = MyKmeans(df=data_df,n_cluster=4, c_initial=range(1,5))\n",
    "plt.scatter(MyRes4.iloc[:,0],MyRes4.iloc[:,1], c=MyRes4.iloc[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 2 - Using kmeans from scikit-learn\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the things we've done so far can easily be done using the kmeans function from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run scikit-learn's `KMeans` on our data for two clusters using the same initial centroids as we did before, run:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run scikit-learn's KMeans() on our data for two clusters using the same initial centroids as we did before, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KMeans(n_clusters=2,init=data_df.iloc[0:2,:],max_iter=40)\n",
    "sk_kmeans0=model.fit(data_df)\n",
    "sk_kmeans0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the which clusters the points are assigned to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_kmeans0.predict(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total within sum of squares can be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_kmeans0.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, scikit-learn does not provide a way to directly access values for between-sum-of-squares and total-sum-of-squares. Positions of the centroids can be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_kmeans0.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't have to specify the initial centroids. You can let scikit learn find these. (Indeed, this is what it expects by default, which is why you may have received a warning above). For reproducible results, you can set the seed for random_stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KMeans(n_clusters=2,max_iter=40, random_state=777777)\n",
    "sk_kmeans0=model.fit(data_df)\n",
    "sk_kmeans0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results with those obtained from our implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`KMeans` runs the algorithm multiple times using different starting centroids (10, by default) and returns the one with the best results. It's good practice to try different starting centroids as the clustering results can depend on these. You can change the number of starting centroids that are used using the `n_init` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KMeans(n_clusters=2, n_init=20, max_iter=40, random_state=777777)\n",
    "sk_kmeans0=model.fit(data_df)\n",
    "sk_kmeans0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative `KMeans()` implementations are available in scikit-learn that can be more robust than ours. Look at the documentation for the KMeans() function that's included in your installed version of sklearn.\n",
    "\n",
    "Let's slight alter our `choose_k` function to use the utput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Schoose_k(max_k, data):\n",
    "    #create placeholder lists with the correct number of elements\n",
    "    res = [0] * (max_k+1)\n",
    "    MySS = [0] * (max_k+1)\n",
    "    for i in range(1,max_k+1):\n",
    "        print(\"Trying k means with \",i,\" clusters\")\n",
    "        model=KMeans(n_clusters=i, n_init=20, max_iter=40, random_state=777777)\n",
    "        sk_kmeans0=model.fit(data)\n",
    "        res[i]=sk_kmeans0.inertia_\n",
    "    return res[1:max_k+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above updated version using,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_res = Schoose_k(max_k=k, data=data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results along with ours and compare,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Blue:MyKmeans(), Orange:scikit-learn's KMeans()\")\n",
    "plt.plot(range(1,11),k_res['Tot_Within'], 'o')\n",
    "plt.ylabel(\"Total Within SS\")\n",
    "plt.plot(range(1,11),sk_res, 'o', markersize=4)\n",
    "plt.ylabel(\"Total Within SS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use $k=2$ again and run kmeans() to get the clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_res = KMeans(n_clusters=2, n_init=20, max_iter=40, random_state=777777).fit_predict(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.title(\"MyKmeans clustering\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.scatter(MyRes2.iloc[:,0],MyRes2.iloc[:,1], c=MyRes2.iloc[:,2])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Kmeans() clustering\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.scatter(data_df.iloc[:,0], data_df.iloc[:,1],c=sk_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice in the above plots? Are the results obtained the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 3 - KMeans() on the iris dataset\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris dataset is often used to illustrate clustering and classification and it's also available in sklearn.datasets.\n",
    "\n",
    "The dataset contains the length and width of sepals and petals of different flowers of 3 different species: virginica, versicolor and setosa.\n",
    "\n",
    "In the plot below, the colour corresponds to the flower family of each observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns           # the seaborn library provides a good function for making pair plots\n",
    "import sklearn.datasets as skd  # we use sklearn.datasets to get the iris dataset\n",
    "\n",
    "iris=skd.load_iris()\n",
    "iris_df=pd.DataFrame(iris.data)\n",
    "iris_df.columns=iris.feature_names\n",
    "iris_df['label']=[iris.target_names[t] for t in iris.target]\n",
    "\n",
    "palette=sns.color_palette(\"hls\", 3) # gives a red-green-blue colour palette\n",
    "sns.pairplot(iris_df, hue='label', palette=palette)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see below, the dataset has 50 observations from each species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the pair plot above, could kmeans distinguish between the 3 species? Is there any one with which it could struggle?\n",
    "\n",
    "Let's try kmeans on the iris dataset using the true cluster number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_iris=KMeans(n_clusters=3, n_init=20, max_iter=100, random_state=777777).fit_predict(iris_df.iloc[:,0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df['cluster_label']=cl_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data and colour the points by the assigned clusters. How do the results compare to the true groups? **NOTE:** the colour-cluster combination will not align with those of the previous plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has _k_-means done a good job?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the true class and the assigned clusters using [`crosstab` from Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try scaling your data first before applying kmeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "iris_scaled=scale(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the documentation of `scale` if you're not sure what it's doing.\n",
    "\n",
    "Run KMeans() on the scaled dataset, using the same seed, and store the results in cl_iris_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the results from k_iris and the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here\n",
    "#comparing with the true labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have the results changed? Has there been any improvement?\n",
    "\n",
    "_Normally_ you would expect scaling to improve the clustering. In fact, in this case, the clustering was already quite successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `Schoose_k` for a series of k values. Would you have chosen $k=3$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Acknowledgements and Reuse\n",
    "<p>\n",
    "<small>\n",
    "Python version by Adam Carter, EPCC, The University of Edinburgh, based on an R version previously created at EPCC, The University of Edinburgh.\n",
    "</small>\n",
    "</p>\n",
    "<p>\n",
    "<small>\n",
    "&copy; 2023 EPCC, The University of Edinburgh\n",
    "</small>\n",
    "</p>\n",
    "<p>\n",
    "<small>\n",
    "You are welcome to re-use this notebook and its contents under the terms of CC-BY-4.0\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
